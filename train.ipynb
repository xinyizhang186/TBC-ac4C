{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b23d679c-1e22-4faf-87a3-6b9b2b864ebd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ntrain.py provides complete model training, validation, and evaluation functions, including early stopping mechanism, learning rate scheduling, and k-fold cross-validation.\\n\\nMain functions:\\n  1. Early stopping mechanism.\\n  2. Model training and validation.\\n  3. k-fold cross-validation.\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import time\n",
    "from termcolor import colored\n",
    "from util.data_loader import construct_dataset\n",
    "from util.util_metric import evaluate, reg_loss\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from model import TBC_ac4C\n",
    "from util.data_loader import load_data, load_bench_data\n",
    "from sklearn.model_selection import train_test_split\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\"\"\"\n",
    "train.py provides complete model training, validation, and evaluation functions, including early stopping mechanism, learning rate scheduling, and k-fold cross-validation.\n",
    "\n",
    "Main functions:\n",
    "  1. Early stopping mechanism.\n",
    "  2. Model training and validation.\n",
    "  3. k-fold cross-validation.\n",
    "\"\"\"\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6c53e909-0bf1-4708-b295-6396f49837ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EarlyStopping:\n",
    "    def __init__(self, patience=10, delta=0.001):\n",
    "        self.patience = patience\n",
    "        self.delta = delta\n",
    "        self.counter = 0\n",
    "        self.best_score = None\n",
    "        self.early_stop = False\n",
    "        self.best_acc = None\n",
    "\n",
    "    def __call__(self, val_acc, model):\n",
    "        score = val_acc\n",
    "        if self.best_score is None:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(val_acc, model)\n",
    "        elif score < self.best_score + self.delta:\n",
    "            self.counter += 1\n",
    "            print(f'EarlyStopping counter: {self.counter} out of {self.patience}')\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "        else:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(val_acc, model)\n",
    "            self.counter = 0\n",
    "\n",
    "    def save_checkpoint(self, val_acc, model):\n",
    "        self.best_acc = val_acc\n",
    "        path = 'best_network.pt'\n",
    "        torch.save(model.state_dict(), path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4a185b17-31f7-4605-a83d-c407afe24caa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test(train_iter, valid_iter, iter_k=1):\n",
    "    net = TBC_ac4C().to(device)\n",
    "    print(net)\n",
    "    lr = 0.00003\n",
    "    optimizer = torch.optim.Adam(net.parameters(), lr=lr)\n",
    "\n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', factor=0.5, patience=5)\n",
    "    early_stopping = EarlyStopping(patience=15, delta=0.0001)\n",
    "\n",
    "    best_acc = 0\n",
    "    EPOCH = 100\n",
    "    for epoch in range(EPOCH):\n",
    "        loss_ls = []\n",
    "        t0 = time.time()\n",
    "\n",
    "        net.train()\n",
    "        for x, label in train_iter:\n",
    "            if device:\n",
    "                x, label = x.to(device), label.to(device)\n",
    "\n",
    "            output = net(x)\n",
    "            loss = reg_loss(net, output, label).to(device)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            loss_ls.append(loss.item())\n",
    "\n",
    "        net.eval()\n",
    "        with torch.no_grad():\n",
    "            train_performance, train_roc_data, train_prc_data, _ = evaluate(train_iter, net)\n",
    "            valid_performance, valid_roc_data, valid_prc_data, label_real = evaluate(valid_iter, net)\n",
    "\n",
    "        results = f\"\\nepoch: {epoch + 1}, loss: {np.mean(loss_ls):.5f}\\n\"\n",
    "        results += f'train_acc: {train_performance[0]:.4f}, time: {time.time() - t0:.2f}'\n",
    "        results += '\\n' + '=' * 16 + ' Valid Performance. Epoch[{}] '.format(epoch + 1) + '=' * 16 \\\n",
    "                   + '\\n[ACC,\\tSE,\\t\\tSP,\\t\\tAUC,\\tMCC]\\n' + '{:.4f},\\t{:.4f},\\t{:.4f},\\t{:.4f},\\t{:.4f}'.format(\n",
    "            valid_performance[0], valid_performance[1], valid_performance[2], valid_performance[3],\n",
    "            valid_performance[4]) + '\\n' + '=' * 60\n",
    "        print(results)\n",
    "\n",
    "        valid_acc = valid_performance[0]  # valid_performance: [ACC, Sensitivity, Specificity, AUC, MCC]\n",
    "\n",
    "        scheduler.step(valid_acc)\n",
    "        if valid_acc > best_acc:\n",
    "            best_acc = valid_acc\n",
    "            best_performance = valid_performance\n",
    "            best_ROC = valid_roc_data\n",
    "            best_PRC = valid_prc_data\n",
    "\n",
    "            if best_acc > 0.85:\n",
    "                filename = '{}, {}[{:.4f}].pt'.format(\n",
    "                    'mRNA_Model' + ', {}折'.format(iter_k + 1) + ', epoch[{}]'.format(epoch + 1), 'ACC', best_acc)\n",
    "                save_path_pt = os.path.join('./Result', filename)  # 路径拼接\n",
    "                torch.save(net.state_dict(), save_path_pt, _use_new_zipfile_serialization=False)\n",
    "\n",
    "                best_ROC = np.array(best_ROC, dtype=object)  # 使用 dtype=object 以处理不规则数组\n",
    "                best_PRC = np.array(best_PRC, dtype=object)\n",
    "                # np.save(\"./Result/{}fold-valid_best_ROC.npy\".format(iter_k + 1), best_ROC)\n",
    "                # np.save(\"./Result/{}fold-valid_best_PRC.npy\".format(iter_k + 1), best_PRC)\n",
    "\n",
    "            best_results = '\\n' + '=' * 16 + colored(' Best Performance. Epoch[{}] ', 'red').format(\n",
    "                epoch + 1) + '=' * 16 \\\n",
    "                           + '\\n[ACC,\\tSE,\\t\\tSP,\\t\\tAUC,\\tMCC]\\n' + '{:.4f},\\t{:.4f},\\t{:.4f},\\t{:.4f},\\t{:.4f}'.format(\n",
    "                best_performance[0], best_performance[1], best_performance[2], best_performance[3],\n",
    "                best_performance[4]) + '\\n' + '=' * 60\n",
    "\n",
    "        early_stopping(valid_acc, net)\n",
    "        if early_stopping.early_stop:\n",
    "            print(\"Early stopping\")\n",
    "            break\n",
    "\n",
    "    return best_performance, best_results, best_ROC, best_PRC\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fe72a101-c4d4-4f5b-90c6-0e4d57f966e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def K_CV(file, k=10):\n",
    "    seqs = load_data(file)\n",
    "    labels = np.vstack((np.ones((int(4412 / 2), 1), dtype=int), np.zeros((int(4412 / 2), 1), dtype=int))).flatten()\n",
    "    seqs, labels = np.array(seqs), np.array(labels)\n",
    "    CV_perform = []\n",
    "\n",
    "    kfold = StratifiedKFold(n_splits=k, shuffle=True, random_state=2025)\n",
    "    for iter_k, (train_index, test_index) in enumerate(kfold.split(seqs, labels)):\n",
    "        print(\"\\n\" + \"=\" * 16 + \"k = \" + str(iter_k + 1) + \"=\" * 16)\n",
    "\n",
    "        train_seqs, test_seqs = seqs[train_index], seqs[test_index]\n",
    "        train_lables, test_labels = labels[train_index], labels[test_index]\n",
    "        train_iter = construct_dataset(train_seqs, train_lables, train=True)\n",
    "        test_iter = construct_dataset(test_seqs, test_labels, train=False)\n",
    "\n",
    "        performance, _, ROC, PRC = train_test(train_iter, test_iter, iter_k)\n",
    "        print('交叉验证: best_performance', performance)\n",
    "        CV_perform.append(performance)\n",
    "\n",
    "\n",
    "    print('\\n' + '=' * 16 + colored(' Cross-Validation Performance ',\n",
    "                                    'red') + '=' * 16 + '\\n[ACC,\\tSE,\\t\\tSP,\\t\\tAUC,\\tMCC]\\n')\n",
    "    for k, out in enumerate(CV_perform):\n",
    "        print( '第{}折: {:.4f},\\t{:.4f},\\t{:.4f},\\t{:.4f},\\t{:.4f}'.format(k + 1, out[0],\n",
    "                                          out[1], out[2], out[3], out[4]))\n",
    "\n",
    "    mean_out = np.array(CV_perform).mean(axis=0)  # 计算所有交叉验证迭代性能指标的平均值。\n",
    "    print('\\n' + '=' * 16 + \"Mean out\" + '=' * 16)  # [ACC, Sensitivity, Specificity, AUC, MCC]\n",
    "\n",
    "    print('ACC: {:.4f},\\tSE: {:.4f},\\tSP: {:.4f},\\tAUC: {:.4f},\\tMCC: {:.4f}'.format( \\\n",
    "        mean_out[0], mean_out[1], mean_out[2], mean_out[3], mean_out[4]))\n",
    "    print('\\n' + '=' * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b146cd79-2af1-4b10-9f27-e0c0808f4a5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TBC_ac4C(\n",
      "  (embedding): Embedding(\n",
      "    (tok_embed): Embedding(5, 64)\n",
      "    (pos_embed): Embedding(201, 64)\n",
      "    (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "  )\n",
      "  (encoder_layer): TransformerEncoderLayer(\n",
      "    (self_attn): MultiheadAttention(\n",
      "      (out_proj): NonDynamicallyQuantizableLinear(in_features=64, out_features=64, bias=True)\n",
      "    )\n",
      "    (linear1): Linear(in_features=64, out_features=2048, bias=True)\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "    (linear2): Linear(in_features=2048, out_features=64, bias=True)\n",
      "    (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "    (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "    (dropout1): Dropout(p=0.1, inplace=False)\n",
      "    (dropout2): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      "  (transformer_encoder): TransformerEncoder(\n",
      "    (layers): ModuleList(\n",
      "      (0-2): 3 x TransformerEncoderLayer(\n",
      "        (self_attn): MultiheadAttention(\n",
      "          (out_proj): NonDynamicallyQuantizableLinear(in_features=64, out_features=64, bias=True)\n",
      "        )\n",
      "        (linear1): Linear(in_features=64, out_features=2048, bias=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "        (linear2): Linear(in_features=2048, out_features=64, bias=True)\n",
      "        (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "        (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "        (dropout1): Dropout(p=0.1, inplace=False)\n",
      "        (dropout2): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "    )\n",
      "    (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "  )\n",
      "  (tcv): TemporalConvNet(\n",
      "    (network): Sequential(\n",
      "      (0): TemporalBlock(\n",
      "        (conv1): Conv1d(64, 64, kernel_size=(5,), stride=(1,), padding=(4,))\n",
      "        (chomp1): Chomp1d()\n",
      "        (relu1): ReLU()\n",
      "        (dropout1): Dropout(p=0.1, inplace=False)\n",
      "        (conv2): Conv1d(64, 64, kernel_size=(5,), stride=(1,), padding=(4,))\n",
      "        (chomp2): Chomp1d()\n",
      "        (relu2): ReLU()\n",
      "        (dropout2): Dropout(p=0.1, inplace=False)\n",
      "        (net): Sequential(\n",
      "          (0): Conv1d(64, 64, kernel_size=(5,), stride=(1,), padding=(4,))\n",
      "          (1): Chomp1d()\n",
      "          (2): ReLU()\n",
      "          (3): Dropout(p=0.1, inplace=False)\n",
      "          (4): Conv1d(64, 64, kernel_size=(5,), stride=(1,), padding=(4,))\n",
      "          (5): Chomp1d()\n",
      "          (6): ReLU()\n",
      "          (7): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (relu): ReLU()\n",
      "      )\n",
      "      (1): TemporalBlock(\n",
      "        (conv1): Conv1d(64, 64, kernel_size=(5,), stride=(1,), padding=(8,), dilation=(2,))\n",
      "        (chomp1): Chomp1d()\n",
      "        (relu1): ReLU()\n",
      "        (dropout1): Dropout(p=0.1, inplace=False)\n",
      "        (conv2): Conv1d(64, 64, kernel_size=(5,), stride=(1,), padding=(8,), dilation=(2,))\n",
      "        (chomp2): Chomp1d()\n",
      "        (relu2): ReLU()\n",
      "        (dropout2): Dropout(p=0.1, inplace=False)\n",
      "        (net): Sequential(\n",
      "          (0): Conv1d(64, 64, kernel_size=(5,), stride=(1,), padding=(8,), dilation=(2,))\n",
      "          (1): Chomp1d()\n",
      "          (2): ReLU()\n",
      "          (3): Dropout(p=0.1, inplace=False)\n",
      "          (4): Conv1d(64, 64, kernel_size=(5,), stride=(1,), padding=(8,), dilation=(2,))\n",
      "          (5): Chomp1d()\n",
      "          (6): ReLU()\n",
      "          (7): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (relu): ReLU()\n",
      "      )\n",
      "      (2): TemporalBlock(\n",
      "        (conv1): Conv1d(64, 100, kernel_size=(5,), stride=(1,), padding=(16,), dilation=(4,))\n",
      "        (chomp1): Chomp1d()\n",
      "        (relu1): ReLU()\n",
      "        (dropout1): Dropout(p=0.1, inplace=False)\n",
      "        (conv2): Conv1d(100, 100, kernel_size=(5,), stride=(1,), padding=(16,), dilation=(4,))\n",
      "        (chomp2): Chomp1d()\n",
      "        (relu2): ReLU()\n",
      "        (dropout2): Dropout(p=0.1, inplace=False)\n",
      "        (net): Sequential(\n",
      "          (0): Conv1d(64, 100, kernel_size=(5,), stride=(1,), padding=(16,), dilation=(4,))\n",
      "          (1): Chomp1d()\n",
      "          (2): ReLU()\n",
      "          (3): Dropout(p=0.1, inplace=False)\n",
      "          (4): Conv1d(100, 100, kernel_size=(5,), stride=(1,), padding=(16,), dilation=(4,))\n",
      "          (5): Chomp1d()\n",
      "          (6): ReLU()\n",
      "          (7): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (downsample): Conv1d(64, 100, kernel_size=(1,), stride=(1,))\n",
      "        (relu): ReLU()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (BiGRU): GRU(64, 50, num_layers=2, batch_first=True, dropout=0.3, bidirectional=True)\n",
      "  (cross): CrossAttention(\n",
      "    (proj_q1): Linear(in_features=100, out_features=384, bias=False)\n",
      "    (proj_k2): Linear(in_features=100, out_features=384, bias=False)\n",
      "    (proj_v2): Linear(in_features=100, out_features=384, bias=False)\n",
      "    (proj_o): Linear(in_features=384, out_features=100, bias=True)\n",
      "    (drop): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      "  (shapeChange): Sequential(\n",
      "    (0): Linear(in_features=201, out_features=512, bias=True)\n",
      "    (1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "    (2): GELU(approximate='none')\n",
      "  )\n",
      "  (classifier): Sequential(\n",
      "    (0): Linear(in_features=100, out_features=64, bias=True)\n",
      "    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): Dropout(p=0.3, inplace=False)\n",
      "    (3): LeakyReLU(negative_slope=0.01)\n",
      "    (4): Linear(in_features=64, out_features=2, bias=True)\n",
      "    (5): Softmax(dim=1)\n",
      "  )\n",
      ")\n",
      "Trainable Parameter: 1641786\n",
      "\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':  \n",
    "    net = TBC_ac4C().to(device)\n",
    "    print(net)\n",
    "    model_parameters = filter(lambda p: p.requires_grad, net.parameters())\n",
    "    params = sum([np.prod(p.size()) for p in model_parameters])\n",
    "    print(\"Trainable Parameter: \" + str(params) + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8bfbd47-9335-42ad-9c86-add433aec4ba",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
